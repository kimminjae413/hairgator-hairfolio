import React, { useState, useRef } from 'react';
import { useTranslation } from 'react-i18next';
import { useColorTryOn, ColorTryOnRequest } from '../services/geminiColorService';
import { detectFaceFromFile, getFaceShapeRecommendation, FaceDetectionResult } from '../services/faceDetectionService';

interface ColorTryOnModalProps {
  colorStyleImage: {
    name: string;
    url: string;
    serviceSubCategory?: string;
    description?: string;
  };
  userFaceFile?: File | null;
  userFacePreview?: string | null;
  onClose: () => void;
  onComplete: (result: any) => void;
}

const ColorTryOnModal: React.FC<ColorTryOnModalProps> = ({
  colorStyleImage,
  userFaceFile: initialFaceFile,
  userFacePreview: initialFacePreview,
  onClose,
  onComplete
}) => {
  const { t } = useTranslation();
  
  const [userPhoto, setUserPhoto] = useState<File | null>(initialFaceFile || null);
  const [previewUrl, setPreviewUrl] = useState<string | null>(initialFacePreview || null);
  
  // ì–¼êµ´ ì¸ì‹ ê²°ê³¼ ìƒíƒœ ì¶”ê°€
  const [faceDetection, setFaceDetection] = useState<FaceDetectionResult | null>(null);
  const [isFaceDetecting, setIsFaceDetecting] = useState(false);
  
  const [colorType, setColorType] = useState<'highlight' | 'full-color' | 'ombre' | 'balayage'>('full-color');
  const [intensity, setIntensity] = useState<'light' | 'medium' | 'bold'>('medium');
  const [currentStep, setCurrentStep] = useState<'upload' | 'options' | 'processing' | 'result'>(
    initialFaceFile ? 'options' : 'upload'
  );
  
  const { isProcessing, result, error, tryOnColor } = useColorTryOn();
  const fileInputRef = useRef<HTMLInputElement>(null);
  const modalRef = useRef<HTMLDivElement>(null);

  // ì–¼êµ´ ì¸ì‹ì´ í†µí•©ëœ íŒŒì¼ ì—…ë¡œë“œ í•¸ë“¤ëŸ¬
  const handleFileUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;

    // íŒŒì¼ íƒ€ì… ê²€ì¦
    if (!file.type.startsWith('image/')) {
      alert('ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
      return;
    }

    // íŒŒì¼ í¬ê¸° ê²€ì¦ (10MB)
    if (file.size > 10 * 1024 * 1024) {
      alert('íŒŒì¼ í¬ê¸°ëŠ” 10MB ì´í•˜ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.');
      return;
    }

    // ë¯¸ë¦¬ë³´ê¸° ì„¤ì •
    setUserPhoto(file);
    if (previewUrl && previewUrl !== initialFacePreview) {
      URL.revokeObjectURL(previewUrl);
    }
    const newPreviewUrl = URL.createObjectURL(file);
    setPreviewUrl(newPreviewUrl);
    
    // ì–¼êµ´ ì¸ì‹ ì‹œì‘
    setIsFaceDetecting(true);
    setFaceDetection(null);
    
    try {
      console.log('ğŸ” ì–¼êµ´ ì¸ì‹ ì‹œì‘...');
      const detection = await detectFaceFromFile(file);
      setFaceDetection(detection);
      
      if (detection.detected) {
        console.log('âœ… ì–¼êµ´ ê°ì§€ ì„±ê³µ:', detection.faceShape);
      } else {
        console.warn('âš ï¸ ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨:', detection.message);
      }
    } catch (err) {
      console.error('âŒ ì–¼êµ´ ì¸ì‹ ì˜¤ë¥˜:', err);
      setFaceDetection({
        detected: false,
        message: 'ì–¼êµ´ ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
      });
    } finally {
      setIsFaceDetecting(false);
      setCurrentStep('options');
    }
  };

  const handleStartTryOn = async () => {
    if (!userPhoto) return;

    setCurrentStep('processing');

    const userPhotoUrl = previewUrl || URL.createObjectURL(userPhoto);

    const request: ColorTryOnRequest = {
      userPhotoUrl,
      colorStyleUrl: colorStyleImage.url,
      colorType,
      intensity,
      colorName: colorStyleImage.name
    };

    try {
      await tryOnColor(request);
      setCurrentStep('result');
    } catch (err) {
      console.error('Color try-on failed:', err);
      setCurrentStep('options');
    }
  };

  const handleModalClick = (e: React.MouseEvent) => {
    if (e.target === modalRef.current) {
      onClose();
    }
  };

  const colorTypeLabels = {
    'full-color': 'ì „ì²´ ì—¼ìƒ‰',
    'highlight': 'í•˜ì´ë¼ì´íŠ¸',
    'ombre': 'ì˜´ë¸Œë ˆ',
    'balayage': 'ë°œë ˆì•„ì¥¬'
  };

  const intensityLabels = {
    'light
